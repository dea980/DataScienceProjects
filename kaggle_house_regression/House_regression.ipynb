{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## House Regression EDA Notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import the following library functions\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATA READGING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_train = pd.read_csv('/content/hp_train.csv') ## this might be on the directory\n",
    "hp_test = pd.read_csv('/content/hp_test.csv')\n",
    "# Shape and preview\n",
    "print('Train set shape:', hp_train.shape)\n",
    "print('Test set shape:', hp_test.shape)\n",
    "hp_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing & Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Handling missing values\n",
    "## missing value check\n",
    "print('Missing values from train set:')\n",
    "print(hp_train.isna().sum())\n",
    "print('Missign values from test set:')\n",
    "print(hp_test.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get information from the train and test sets\n",
    "## Train set\n",
    "hp_train.head(3)\n",
    "## TEST set\n",
    "hp_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get more information from the train and test sets\n",
    "## Train set\n",
    "hp_train.discribe()\n",
    "## test set\n",
    "hp_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "categorical = (hp_train.dtypes == object)\n",
    "categorical1 = (hp_test.dtypes == object)\n",
    "categorical\n",
    "\n",
    "for col in range(len(hp_train.columns)):\n",
    "  if categorical[col] == True :\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    hp_train.iloc[:, col] = le.fit_transform(hp_train.iloc[:,col])\n",
    "\n",
    "for col in range(len(hp_test.columns)):\n",
    "  if categorical1[col] == True :\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    hp_test.iloc[:, col] = le.fit_transform(hp_test.iloc[:,col])\n",
    "hp_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## we need to figure out Correlation between Price and other parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "corr_matrix = hp_train.corr()\n",
    "corr_df = pd.DataFrame(corr_matrix[\"SalePrice\"].sort_values(ascending=False))\n",
    "corr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pick the selected training parameters by correlation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## correlation matrix  might need correaltion with the sale prices\n",
    "hp_train_subset = hp_train[[\"SalePrice\",\"OverallQual\",\"GrLivArea\", \"GarageCars\",\"GarageArea\",\"TotalBsmtSF\",\"1stFlrSF\",\"FullBath\",\"TotRmsAbvGrd\",\"YearBuilt\",\"YearRemodAdd\",\"GarageYrBlt\",\"MasVnrArea\",\"Fireplaces\"]]\n",
    "hp_train_subset\n",
    "hp_test_subset = hp_test[[\"OverallQual\",\"GrLivArea\", \"GarageCars\",\"GarageArea\",\"TotalBsmtSF\",\"1stFlrSF\",\"FullBath\",\"TotRmsAbvGrd\",\"YearBuilt\",\"YearRemodAdd\",\"GarageYrBlt\",\"MasVnrArea\",\"Fireplaces\"]]\n",
    "hp_test_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find all missing values in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## finding the missing value\n",
    "print(hp_train_subset.isna().sum())\n",
    "##  compare with the missing values from the original data\n",
    "print(hp_train['SalePrice'].isna().sum())\n",
    "print(hp_train['OverallQual'].isna().sum())\n",
    "print(hp_train['GrLivArea'].isna().sum())\n",
    "print(hp_train['GarageCars'].isna().sum())\n",
    "print(hp_train['GarageArea'].isna().sum())\n",
    "print(hp_train['TotalBsmtSF'].isna().sum())\n",
    "print(hp_train['1stFlrSF'].isna().sum())\n",
    "print(hp_train['FullBath'].isna().sum())\n",
    "print(hp_train['TotRmsAbvGrd'].isna().sum())\n",
    "print(hp_train['YearBuilt'].isna().sum())\n",
    "print(hp_train['YearRemodAdd'].isna().sum())\n",
    "print(hp_train['GarageYrBlt'].isna().sum())##\n",
    "print(hp_train['MasVnrArea'].isna().sum())##\n",
    "print(hp_train['Fireplaces'].isna().sum())\n",
    "print(hp_test_subset.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find all missings in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_test_subset.isna().sum()\n",
    "#len(hp_test_subset)\n",
    "hp_test_subset['GarageCars'] = hp_test_subset['GarageCars'].replace(np.nan, np.nanmean(hp_test_subset.loc[:'GarageCars']))\n",
    "hp_test_subset['GarageArea'] = hp_test_subset['GarageArea'].replace(np.nan, np.nanmean(hp_test_subset.loc[:,'GarageArea']))\n",
    "hp_test_subset['TotalBsmtSF'] = hp_test_subset['TotalBsmtSF'].replace(np.nan, np.nanmean(hp_test_subset.loc[:,'TotalBsmtSF']))\n",
    "\n",
    "#hp_test_subset = hp_test_subset[hp_test_subset['TotalBsmtSF'].notna()]\n",
    "\n",
    "hp_test_subset['GarageYrBlt'] = hp_test_subset['GarageYrBlt'].replace(np.nan, np.nanmean(hp_test_subset.loc[:,'GarageYrBlt']))\n",
    "hp_test_subset['MasVnrArea'] = hp_test_subset['MasVnrArea'].replace(np.nan,0)\n",
    "hp_test_subset.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check that subset contains with training subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "hp_train_subset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check that subset contains with training subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## missing value check\n",
    "print('TRAIN SET MISSING VALUES:')\n",
    "print(hp_train.isna().sum())\n",
    "print('')\n",
    "print('TEST SET MISSING VALUES:')\n",
    "print(hp_test.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the scatter plots for training set with feature values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "plt.title(\"Gross Living Area and Sale Price\")\n",
    "line_params = np.polyfit(hp_train.loc[:,'GrLivArea'], hp_train.loc[:,'SalePrice'], 1)\n",
    "line = line_params[1] + line_params[0] * hp_train.loc[:,'GrLivArea']\n",
    "plt.plot(hp_train.loc[:,'GrLivArea'], line, 'r')\n",
    "plt.scatter(x = hp_train.loc[:,'GrLivArea'],y = hp_train.loc[:,'SalePrice'] , color = 'yellow')\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.title(\"Year Built and Sale Price\")\n",
    "line_params = np.polyfit(hp_train.loc[:,'YearBuilt'], hp_train.loc[:,'SalePrice'], 1)\n",
    "line = line_params[1] + line_params[0] * hp_train.loc[:,'YearBuilt']\n",
    "plt.plot(hp_train.loc[:,'YearBuilt'], line, 'r')\n",
    "plt.scatter(x = hp_train.loc[:,'YearBuilt'],y= hp_train.loc[:,'SalePrice'] , color = 'orange')\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.title(\"Garage Area and Sale Price\")\n",
    "line_params = np.polyfit(hp_train.loc[:,'GarageArea'], hp_train.loc[:,'SalePrice'], 1)\n",
    "line = line_params[1] + line_params[0] * hp_train.loc[:,'GarageArea']\n",
    "plt.plot(hp_train.loc[:,'GarageArea'], line, 'r')\n",
    "plt.scatter(x = hp_train.loc[:,'GarageArea'],y= hp_train.loc[:,'SalePrice'] , color = 'purple')\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.title(\"Year of Remodel and Sale Price\")\n",
    "line_params = np.polyfit(hp_train.loc[:,'YearRemodAdd'], hp_train.loc[:,'SalePrice'], 1)\n",
    "line = line_params[1] + line_params[0] * hp_train.loc[:,'YearRemodAdd']\n",
    "plt.plot(hp_train.loc[:,'YearRemodAdd'], line, 'r')\n",
    "plt.scatter(x = hp_train.loc[:,'YearRemodAdd'],y = hp_train.loc[:,'SalePrice'] , color = 'green')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Attributes Distributions by histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hp_train_subset.head(5))\n",
    "plt.figure(figsize = (16,12))\n",
    "\n",
    "plt.subplot(2,4,1)\n",
    "sns.distplot(hp_train.loc[:,'SalePrice'], color = 'red')\n",
    "\n",
    "plt.subplot(2,4,2)\n",
    "sns.distplot(hp_train.loc[:,'GrLivArea'], color = 'blue')\n",
    "\n",
    "plt.subplot(2,4,3)\n",
    "sns.distplot(hp_train.loc[:,'YearBuilt'], color = 'yellow')\n",
    "\n",
    "plt.subplot(2,4,4)\n",
    "sns.distplot(hp_train.loc[:,'YearRemodAdd'], color = 'green')\n",
    "\n",
    "plt.subplot(2,4,5)\n",
    "plt.hist(hp_train.loc[:,'OverallQual'], color = 'orange')\n",
    "\n",
    "plt.subplot(2,4,6)\n",
    "plt.hist(hp_train.loc[:,'GarageCars'], color = 'blue')\n",
    "\n",
    "plt.subplot(2,4,7)\n",
    "plt.hist(hp_train.loc[:,'FullBath'], color = 'pink')\n",
    "\n",
    "plt.subplot(2,4,8)\n",
    "plt.hist(hp_train.loc[:,'TotRmsAbvGrd'], color = 'purple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "hp_train_subset['GarageYrBlt'] = hp_train_subset['GarageYrBlt'].replace(np.nan, np.nanmean(hp_train_subset.loc[:,'GarageYrBlt']))\n",
    "hp_train_subset['MasVnrArea'] = hp_train_subset['MasVnrArea'].replace(np.nan,0)\n",
    "hp_train_subset.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# in this case, we found Sale price has a slightly right skewed normal distribution "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test with the box plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,12))\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "sns.boxplot(x = hp_train[\"FullBath\"], y = hp_train[\"SalePrice\"])\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "sns.boxplot(x = hp_train[\"Fireplaces\"], y = hp_train[\"SalePrice\"])\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "sns.boxplot(x = hp_train[\"TotRmsAbvGrd\"], y = hp_train[\"SalePrice\"])\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "sns.boxplot(x = hp_train[\"OverallQual\"], y = hp_train[\"SalePrice\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(hp_train.loc[:,'SalePrice'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create with the standarize the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardize the columns\n",
    "import statistics\n",
    "for col in range(len(hp_train_subset.columns) - 1):\n",
    "  mean = hp_train_subset.iloc[:,col].mean()\n",
    "  std = statistics.stdev(hp_train_subset.iloc[:,col])\n",
    "  for row in range(len(hp_train_subset.columns)):\n",
    "    hp_train_subset.iloc[row,col] = hp_train_subset.iloc[row,col] - mean / std\n",
    "for col in range(len(hp_test_subset.columns) - 1):\n",
    "  mean = hp_test_subset.iloc[:,col].mean()\n",
    "  std = statistics.stdev(hp_test_subset.iloc[:,col])\n",
    "  for row in range(len(hp_test_subset.columns)):\n",
    "    hp_test_subset.iloc[row,col] = hp_test_subset.iloc[row,col] - mean / std\n",
    "hp_test_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learing Model(Modeling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "hp_train_subset = hp_train_subset.reindex(columns = [\"OverallQual\",\"GrLivArea\", \"GarageCars\",\"GarageArea\",\"TotalBsmtSF\",\"1stFlrSF\",\"FullBath\",\"TotRmsAbvGrd\",\"YearBuilt\",\"YearRemodAdd\",\"GarageYrBlt\",\"MasVnrArea\",\"Fireplaces\",\"SalePrice\"])\n",
    "\n",
    "hp_X_train = hp_train_subset.iloc[:,0:len(hp_train_subset.columns) - 1]\n",
    "hp_y_train = hp_train_subset.iloc[:,len(hp_train_subset.columns) - 1]\n",
    "reg = LinearRegression()\n",
    "lr_scores = cross_val_score(reg, hp_X_train, hp_y_train, cv=5)\n",
    "\n",
    "hp_train = pd.read_csv('/content/hp_train.csv')\n",
    "hp_X_train_full = hp_train.iloc[:, 0:len(hp_train.columns) - 1]\n",
    "hp_y_train_full = hp_train.iloc[:, len(hp_train.columns) - 1]\n",
    "\n",
    "reg = LinearRegression().fit(hp_X_train, hp_y_train)\n",
    "pred = pd.DataFrame(reg.predict(hp_test_subset))\n",
    "pred.columns = ['SalePrice']\n",
    "pred['Id'] = hp_test['Id']\n",
    "hp_train_subset.isna().sum()\n",
    "pred = pred.reindex(columns = ['Id','SalePrice'])\n",
    "print(pred)\n",
    "pred.to_csv(\"submission.csv\", index=False)\n",
    "#print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "rfg = RandomForestRegressor().fit(hp_X_train,hp_y_train )\n",
    "rfg_scores = cross_val_score(rfg, hp_X_train, hp_y_train, cv=5)\n",
    "pred1 = pd.DataFrame(rfg.predict(hp_test_subset))\n",
    "pred1.columns = ['SalePrice']\n",
    "pred1['Id'] = hp_test['Id']\n",
    "pred1 = pred1[['Id','SalePrice']]\n",
    "pred1.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "pred1\n",
    "rfg_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supoort Vector Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "svr_scores = cross_val_score(SVR(), hp_X_train, hp_y_train, cv=5)\n",
    "svr = SVR().fit(hp_X_train, hp_y_train)\n",
    "svr_pred = pd.DataFrame(svr.predict(hp_test_subset))\n",
    "print(svr_scores)\n",
    "svr_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Regressor ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbreg = GradientBoostingRegressor().fit(hp_X_train, hp_y_train)\n",
    "gbr_scores = cross_val_score(GradientBoostingRegressor(), hp_X_train, hp_y_train, cv=5)\n",
    "\n",
    "pred = pd.DataFrame(gbreg.predict(hp_test_subset))\n",
    "pred.columns = ['SalePrice']\n",
    "pred['Id'] = hp_test['Id']\n",
    "hp_train_subset.isna().sum()\n",
    "pred = pred.reindex(columns = ['Id','SalePrice'])\n",
    "print(pred)\n",
    "pred.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "dt_scores = cross_val_score(DecisionTreeRegressor(), hp_X_train, hp_y_train, cv = 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Ridge Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import BayesianRidge\n",
    "\n",
    "br_scores = cross_val_score(BayesianRidge(), hp_X_train, hp_y_train,cv = 5)\n",
    "br_scores\n",
    "np.mean(br_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "\n",
    "lass_scores = cross_val_score(linear_model.Lasso(alpha = .1), hp_X_train, hp_y_train,cv = 5)\n",
    "\n",
    "lass_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "mlp_scores = cross_val_score(MLPRegressor(max_iter = 1000), hp_X_train, hp_y_train, cv = 5)\n",
    "mlp_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "knn_scores = cross_val_score(neighbors.KNeighborsRegressor(n_neighbors = 5) , hp_X_train, hp_y_train, cv = 5)\n",
    "\n",
    "knn_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODES TABEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores = pd.DataFrame(columns = ['Model','Score'])\n",
    "df_scores['Model'] = ['Linear Regression', 'Random Forest Regression','Support Vector Regressor', 'Gradient Boosting Regressor', 'Decision Tree Regressor', 'Bayesian Ridge Regression', 'Lasso Regression', 'MLP Regressor', 'KNN Regressor']\n",
    "df_scores['Score'] = [np.mean(lr_scores), np.mean(rfg_scores), np.mean(svr_scores), np.mean(gbr_scores), np.mean(dt_scores), np.mean(br_scores), np.mean(lass_scores), np.mean(mlp_scores), np.mean(knn_scores)]\n",
    "#df_scores.loc[0,'Model'] = 'Linear Regression'\n",
    "#df_scores.loc[1,'Model']\n",
    "df_scores #.sort_values(by = 'Score', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbreg = GradientBoostingRegressor().fit(hp_X_train, hp_y_train)\n",
    "gbr_scores = cross_val_score(GradientBoostingRegressor(), hp_X_train, hp_y_train, cv=5)\n",
    "\n",
    "pred = pd.DataFrame(gbreg.predict(hp_test_subset))\n",
    "pred.columns = ['SalePrice']\n",
    "pred['Id'] = hp_test['Id']\n",
    "hp_train_subset.isna().sum()\n",
    "pred = pred.reindex(columns = ['Id','SalePrice'])\n",
    "print(pred)\n",
    "pred.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
